{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations Management\n",
    "\n",
    "The `aLLMConfigs` class enables you to **view, customize, and manage** model configurations used by `azLLM`.\n",
    "\n",
    "You can work in two modes:\n",
    "\n",
    "- **Default mode**: Uses built-in configurations per client.\n",
    "- **Custom mode**: Lets you define your own configurations.\n",
    "\n",
    "> **NOTE:** Once `azLLM` is initialized with custom configurations, it will no longer use default ones in that session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Default Configurations\n",
    "\n",
    "Default configurations are pre-defined for each supported client (e.g., OpenAI, DeepSeek, Grok, Fireworks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azllm import azLLMConfigs\n",
    "\n",
    "configmanager = azLLMConfigs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'grok-2-latest',\n",
       " 'system_message': 'You are an advanced AI assistant.',\n",
       " 'temperature': 1,\n",
       " 'max_tokens': 4096,\n",
       " 'frequency_penalty': 0,\n",
       " 'presence_penalty': 0,\n",
       " 'kwargs': {}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configmanager.get_default_configs('grok')    # Get configs for a specific client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openai': {'model': 'gpt-4o-mini',\n",
       "  'system_message': 'You are an advanced AI assistant.',\n",
       "  'temperature': 1,\n",
       "  'max_tokens': 4096,\n",
       "  'frequency_penalty': 0,\n",
       "  'presence_penalty': 0,\n",
       "  'kwargs': {}},\n",
       " 'deepseek': {'model': 'deepseek-chat',\n",
       "  'system_message': 'You are an advanced AI assistant.',\n",
       "  'temperature': 1.3,\n",
       "  'max_tokens': 4096,\n",
       "  'frequency_penalty': 0,\n",
       "  'presence_penalty': 0,\n",
       "  'stream': False,\n",
       "  'kwargs': {}},\n",
       " 'grok': {'model': 'grok-2-latest',\n",
       "  'system_message': 'You are an advanced AI assistant.',\n",
       "  'temperature': 1,\n",
       "  'max_tokens': 4096,\n",
       "  'frequency_penalty': 0,\n",
       "  'presence_penalty': 0,\n",
       "  'kwargs': {}},\n",
       " 'anthropic': {'model': 'claude-3-7-sonnet-20250219',\n",
       "  'system_message': 'You are an advanced AI assistant.',\n",
       "  'temperature': 1,\n",
       "  'max_tokens': 4096,\n",
       "  'frequency_penalty': 0,\n",
       "  'presence_penalty': 0,\n",
       "  'kwargs': {}},\n",
       " 'gemini': {'model': 'gemini-2.0-flash',\n",
       "  'system_message': 'You are an advanced AI assistant.',\n",
       "  'temperature': 1,\n",
       "  'max_tokens': 4096,\n",
       "  'frequency_penalty': 0,\n",
       "  'presence_penalty': 0,\n",
       "  'kwargs': {}},\n",
       " 'ollama': {'model': 'tinyllama:1.1b',\n",
       "  'system_message': 'You are an advanced AI assistant.',\n",
       "  'temperature': 1,\n",
       "  'max_tokens': 4096,\n",
       "  'frequency_penalty': 0,\n",
       "  'presence_penalty': 0,\n",
       "  'kwargs': {}},\n",
       " 'fireworks': {'model': 'accounts/fireworks/models/llama4-scout-instruct-basic',\n",
       "  'system_message': 'You are an advanced AI assistant.',\n",
       "  'temperature': 1,\n",
       "  'max_tokens': 4096,\n",
       "  'frequency_penalty': 0,\n",
       "  'presence_penalty': 0,\n",
       "  'kwargs': {}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configmanager.get_default_configs('all')     # Get configs for all clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Custom Configurations\n",
    "\n",
    "\n",
    "To define your own model configurations, initialize `aLLMConfigs` with `custom=True`.  \n",
    "This will create a local configuration file at:  `custom_configs/config.yaml`\n",
    "\n",
    "You can: \n",
    "- Edit the config file manually, or  \n",
    "- Programmatically update it using `update_custom_configs()`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why use custom configurations?\n",
    "\n",
    "\n",
    "Custom configs give you control over:\n",
    "- Response style (via `system_message`)\n",
    "- Creativity (`temperature`)\n",
    "- Output length (`max_tokens`)\n",
    "- Repetition control (`frequency_penalty`, `presence_penalty`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Creating & Updating Custom Configurations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template YAML file created at /Users/hanifsajid/Desktop/venvs/azllm/examples/custom_configs/config.yaml. You can now customize it.\n",
      "Added new model gpt-4o-mini with version v1 for client openai.\n",
      "Custom configurations saved to custom_configs/config.yaml\n",
      "Client deepseek added to custom_configs.\n",
      "Added new model deepseek-chat with version v2 for client deepseek.\n",
      "Custom configurations saved to custom_configs/config.yaml\n"
     ]
    }
   ],
   "source": [
    "\n",
    "configmanager = azLLMConfigs(custom=True)\n",
    "\n",
    "example_conf = {\n",
    "    'openai': {\n",
    "        'gpt-4o-mini': {\n",
    "            'version': 'v1',\n",
    "            'parameters': {\n",
    "                'system_message': 'You are an advanced AI assistant',\n",
    "                'temperature': 0.6,\n",
    "                'max_tokens': 1500,\n",
    "                'frequency_penalty': 0.5,\n",
    "                'presence_penalty': 0.1\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'deepseek': {\n",
    "        'deepseek-chat': {\n",
    "            'version': 'v2',\n",
    "            'parameters': {\n",
    "                'system_message': 'You are an advanced AI assistant.',\n",
    "                'temperature': 0.7,\n",
    "                'max_tokens': 1024,\n",
    "                'frequency_penalty': 0,\n",
    "                'presence_penalty': 0\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "for client, models in example_conf.items():\n",
    "    configmanager.update_custom_configs(client, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Custom Configurations\n",
    "\n",
    "After switching to custom mode, access your configurations using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openai': {'models': [{'model': 'gpt-4o-mini',\n",
       "    'parameters': {'frequency_penalty': 0,\n",
       "     'max_tokens': 1024,\n",
       "     'presence_penalty': 0,\n",
       "     'system_message': 'You are a helpful assistant. You always start the output with \"HELLO, I AM AI ASSITANT HS\"',\n",
       "     'temperature': 0.7},\n",
       "    'version': 'default'},\n",
       "   {'model': 'gpt-4o-mini',\n",
       "    'version': 'v1',\n",
       "    'parameters': {'system_message': 'You are an advanced AI assistant',\n",
       "     'temperature': 0.6,\n",
       "     'max_tokens': 1500,\n",
       "     'frequency_penalty': 0.5,\n",
       "     'presence_penalty': 0.1}}]},\n",
       " 'deepseek': {'models': [{'model': 'deepseek-chat',\n",
       "    'version': 'v2',\n",
       "    'parameters': {'system_message': 'You are an advanced AI assistant.',\n",
       "     'temperature': 0.7,\n",
       "     'max_tokens': 1024,\n",
       "     'frequency_penalty': 0,\n",
       "     'presence_penalty': 0}}]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configmanager.custom_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "- If a model's config is missing in custom mode, it may raise an error. Be sure to define all necessary parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azllm-I_5BKfWE-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
